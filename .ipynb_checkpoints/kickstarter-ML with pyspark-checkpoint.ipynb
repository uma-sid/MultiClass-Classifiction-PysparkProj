{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pyspark if its not already installed using the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:07:53.314919Z",
     "iopub.status.busy": "2022-04-24T20:07:53.314583Z",
     "iopub.status.idle": "2022-04-24T20:08:39.636382Z",
     "shell.execute_reply": "2022-04-24T20:08:39.635020Z",
     "shell.execute_reply.started": "2022-04-24T20:07:53.314831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/umasid/opt/anaconda3/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in /Users/umasid/opt/anaconda3/lib/python3.8/site-packages (from pyspark) (0.10.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:39.641580Z",
     "iopub.status.busy": "2022-04-24T20:08:39.641210Z",
     "iopub.status.idle": "2022-04-24T20:08:40.955330Z",
     "shell.execute_reply": "2022-04-24T20:08:40.954454Z",
     "shell.execute_reply.started": "2022-04-24T20:08:39.641521Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "# For scaling the data\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# For PCA\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# for Clustering\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# for dataframe operations\n",
    "from pyspark.sql.functions import when, lit, round, col, ceil\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# for evaluating the clustering results\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "# for balancing the data\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "\n",
    "# import Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# import LogisticRegression classifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Import model evaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# importing the python related libraries for plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T19:55:35.034974Z",
     "iopub.status.busy": "2022-04-14T19:55:35.034444Z",
     "iopub.status.idle": "2022-04-14T19:55:35.040498Z",
     "shell.execute_reply": "2022-04-14T19:55:35.039281Z",
     "shell.execute_reply.started": "2022-04-14T19:55:35.034913Z"
    }
   },
   "source": [
    "## creating the spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:40.957339Z",
     "iopub.status.busy": "2022-04-24T20:08:40.956873Z",
     "iopub.status.idle": "2022-04-24T20:08:47.407961Z",
     "shell.execute_reply": "2022-04-24T20:08:47.406817Z",
     "shell.execute_reply.started": "2022-04-24T20:08:40.957301Z"
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-48d35cc146f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local[*]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ML Implementation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    ".master(\"local[*]\")\\\n",
    ".appName(\"ML Implementation\")\\\n",
    ".getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first import the cleaned dataset exported from the EDA step of R environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T19:55:58.222976Z",
     "iopub.status.busy": "2022-04-14T19:55:58.222669Z",
     "iopub.status.idle": "2022-04-14T19:55:58.227403Z",
     "shell.execute_reply": "2022-04-14T19:55:58.226491Z",
     "shell.execute_reply.started": "2022-04-14T19:55:58.222945Z"
    }
   },
   "source": [
    "# 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:47.413508Z",
     "iopub.status.busy": "2022-04-24T20:08:47.412670Z",
     "iopub.status.idle": "2022-04-24T20:08:54.920693Z",
     "shell.execute_reply": "2022-04-24T20:08:54.919660Z",
     "shell.execute_reply.started": "2022-04-24T20:08:47.413462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "ks_df = spark.read.csv(\"/Users/umasid/My_Workspace/PysparkProj-MultiClass-Classification/dataClean.csv\", header=True, inferSchema=True)\n",
    "ks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:54.922245Z",
     "iopub.status.busy": "2022-04-24T20:08:54.921948Z",
     "iopub.status.idle": "2022-04-24T20:08:55.507936Z",
     "shell.execute_reply": "2022-04-24T20:08:55.506898Z",
     "shell.execute_reply.started": "2022-04-24T20:08:54.922206Z"
    }
   },
   "outputs": [],
   "source": [
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't need some of the columns like launched, deadline and _c0 we will drop them along with the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:55.523375Z",
     "iopub.status.busy": "2022-04-24T20:08:55.518049Z",
     "iopub.status.idle": "2022-04-24T20:08:55.999268Z",
     "shell.execute_reply": "2022-04-24T20:08:55.998265Z",
     "shell.execute_reply.started": "2022-04-24T20:08:55.523300Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecting only the necessary columns\n",
    "ks_df = ks_df.select(['category', 'main_category','currency','backers','country','usd_pledged','usd_goal','launch_gap','state'])\n",
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.000774Z",
     "iopub.status.busy": "2022-04-24T20:08:56.000470Z",
     "iopub.status.idle": "2022-04-24T20:08:56.046207Z",
     "shell.execute_reply": "2022-04-24T20:08:56.045253Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.000736Z"
    }
   },
   "outputs": [],
   "source": [
    "# making a list of columns \n",
    "all_cols = ks_df.columns\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.048345Z",
     "iopub.status.busy": "2022-04-24T20:08:56.047837Z",
     "iopub.status.idle": "2022-04-24T20:08:56.055116Z",
     "shell.execute_reply": "2022-04-24T20:08:56.054404Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.048293Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking at the modified schema\n",
    "ks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.056528Z",
     "iopub.status.busy": "2022-04-24T20:08:56.056260Z",
     "iopub.status.idle": "2022-04-24T20:08:56.071037Z",
     "shell.execute_reply": "2022-04-24T20:08:56.069636Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.056496Z"
    }
   },
   "outputs": [],
   "source": [
    "# listing the categorical columns\n",
    "cat_cols = ['category','main_category','currency','country','state']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.075977Z",
     "iopub.status.busy": "2022-04-24T20:08:56.075445Z",
     "iopub.status.idle": "2022-04-24T20:08:56.087973Z",
     "shell.execute_reply": "2022-04-24T20:08:56.086923Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.075924Z"
    }
   },
   "outputs": [],
   "source": [
    "# listing the category column names after indexing.\n",
    "cat_cols_indexed = ['category_indexed','main_category_indexed','currency_indexed','country_indexed', 'state_indexed']\n",
    "cat_cols_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T10:08:03.14883Z",
     "iopub.status.busy": "2022-04-14T10:08:03.148136Z",
     "iopub.status.idle": "2022-04-14T10:08:03.152891Z",
     "shell.execute_reply": "2022-04-14T10:08:03.151961Z",
     "shell.execute_reply.started": "2022-04-14T10:08:03.148787Z"
    }
   },
   "source": [
    "## Creating a dataframe with numerical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T10:10:27.537351Z",
     "iopub.status.busy": "2022-04-14T10:10:27.537056Z",
     "iopub.status.idle": "2022-04-14T10:10:27.543992Z",
     "shell.execute_reply": "2022-04-14T10:10:27.5426Z",
     "shell.execute_reply.started": "2022-04-14T10:10:27.537319Z"
    }
   },
   "source": [
    "We are going to perform PCA and do clustering on the PCA columns. As PCA is done on only on the continuous variables, we need to subset the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.091554Z",
     "iopub.status.busy": "2022-04-24T20:08:56.091003Z",
     "iopub.status.idle": "2022-04-24T20:08:56.374466Z",
     "shell.execute_reply": "2022-04-24T20:08:56.373495Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.091487Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecting only the necessary columns\n",
    "ks_df_num = ks_df.select(['backers','usd_pledged','usd_goal','launch_gap'])\n",
    "ks_df_num.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T10:10:46.163886Z",
     "iopub.status.busy": "2022-04-14T10:10:46.163075Z",
     "iopub.status.idle": "2022-04-14T10:10:46.167125Z",
     "shell.execute_reply": "2022-04-14T10:10:46.166419Z",
     "shell.execute_reply.started": "2022-04-14T10:10:46.163847Z"
    }
   },
   "source": [
    "# 3. Scale the dataframe with numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.378192Z",
     "iopub.status.busy": "2022-04-24T20:08:56.375865Z",
     "iopub.status.idle": "2022-04-24T20:08:56.414958Z",
     "shell.execute_reply": "2022-04-24T20:08:56.413767Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.378130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the dense vector of all the input features using vector assembler\n",
    "vector_assembler1 = VectorAssembler(inputCols=['backers','usd_pledged','usd_goal','launch_gap'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:56.416642Z",
     "iopub.status.busy": "2022-04-24T20:08:56.416293Z",
     "iopub.status.idle": "2022-04-24T20:08:57.215818Z",
     "shell.execute_reply": "2022-04-24T20:08:57.214899Z",
     "shell.execute_reply.started": "2022-04-24T20:08:56.416599Z"
    }
   },
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "ks_df_scaled1 = vector_assembler1.transform(ks_df)\n",
    "ks_df_scaled1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:08:57.217412Z",
     "iopub.status.busy": "2022-04-24T20:08:57.217054Z",
     "iopub.status.idle": "2022-04-24T20:09:00.583356Z",
     "shell.execute_reply": "2022-04-24T20:09:00.582528Z",
     "shell.execute_reply.started": "2022-04-24T20:08:57.217366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying scaling on the features vector.\n",
    "standard_scaler1 = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "ks_df_scaled1 = standard_scaler1.fit(ks_df_scaled1).transform(ks_df_scaled1)\n",
    "ks_df_scaled1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first reduce the number of dimensions to two using the principal component analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:00.585077Z",
     "iopub.status.busy": "2022-04-24T20:09:00.584742Z",
     "iopub.status.idle": "2022-04-24T20:09:04.912907Z",
     "shell.execute_reply": "2022-04-24T20:09:04.912242Z",
     "shell.execute_reply.started": "2022-04-24T20:09:00.585030Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "pca = PCA(k=2, inputCol='scaled_features', outputCol='pca')\n",
    "model = pca.fit(ks_df_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:04.914023Z",
     "iopub.status.busy": "2022-04-24T20:09:04.913812Z",
     "iopub.status.idle": "2022-04-24T20:09:05.010580Z",
     "shell.execute_reply": "2022-04-24T20:09:05.009763Z",
     "shell.execute_reply.started": "2022-04-24T20:09:04.913988Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform\n",
    "ks_df_pca = model.transform(ks_df_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:05.011859Z",
     "iopub.status.busy": "2022-04-24T20:09:05.011589Z",
     "iopub.status.idle": "2022-04-24T20:09:05.025254Z",
     "shell.execute_reply": "2022-04-24T20:09:05.023614Z",
     "shell.execute_reply.started": "2022-04-24T20:09:05.011804Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking at the datatype of the object ks_df_pca\n",
    "type(ks_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:05.029744Z",
     "iopub.status.busy": "2022-04-24T20:09:05.027086Z",
     "iopub.status.idle": "2022-04-24T20:09:05.335579Z",
     "shell.execute_reply": "2022-04-24T20:09:05.334606Z",
     "shell.execute_reply.started": "2022-04-24T20:09:05.029686Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking at the important columns\n",
    "ks_df_pca.select(['features','scaled_features', 'pca', 'state']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:05.337142Z",
     "iopub.status.busy": "2022-04-24T20:09:05.336826Z",
     "iopub.status.idle": "2022-04-24T20:09:05.545712Z",
     "shell.execute_reply": "2022-04-24T20:09:05.544707Z",
     "shell.execute_reply.started": "2022-04-24T20:09:05.337100Z"
    }
   },
   "outputs": [],
   "source": [
    "# printing the pca vector\n",
    "ks_df_pca.select(['pca']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T10:36:33.4574Z",
     "iopub.status.busy": "2022-04-14T10:36:33.457105Z",
     "iopub.status.idle": "2022-04-14T10:36:33.463557Z",
     "shell.execute_reply": "2022-04-14T10:36:33.462714Z",
     "shell.execute_reply.started": "2022-04-14T10:36:33.457369Z"
    }
   },
   "source": [
    "Now, we have completed the PCA and reduced the dimension to two. We will now apply clustering using these principal componenets and try to visualize the clsters formed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the K-Means Clustering algorithm to cluster the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan for Clustering**\n",
    "\n",
    "1. Find the ideal K-value, which represents the number of clusters.\n",
    "2. Clustering the data using the observed best k-value\n",
    "3. Evaluating the cluster results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding out the best value for K(number of clusters)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:05.547280Z",
     "iopub.status.busy": "2022-04-24T20:09:05.546984Z",
     "iopub.status.idle": "2022-04-24T20:09:05.563346Z",
     "shell.execute_reply": "2022-04-24T20:09:05.562272Z",
     "shell.execute_reply.started": "2022-04-24T20:09:05.547239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the parameters  and creating the object for the evaluator\n",
    "eval = ClusteringEvaluator(predictionCol='prediction', featuresCol='pca', metricName='silhouette', distanceMeasure='squaredEuclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T20:09:05.566194Z",
     "iopub.status.busy": "2022-04-24T20:09:05.565099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trying different possible k-values and finding out the silhouette score for each of those k-values.\n",
    "silhouette_score = []\n",
    "print(\"\"\"\n",
    "Silhoutte Scores for K Mean Clustering\n",
    "=======================================\n",
    "Model\\tScore\\t\n",
    "=====\\t=====\\t\n",
    "\"\"\")\n",
    "for k in range(2,11):\n",
    "    kmeans_algo = KMeans(featuresCol='pca', k=k)\n",
    "    kmeans_fit = kmeans_algo.fit(ks_df_pca)\n",
    "    output = kmeans_fit.transform(ks_df_pca)\n",
    "    score = eval.evaluate(output)\n",
    "    silhouette_score.append(score)\n",
    "    #print(f\"K{k}\\t {round(score,2)}\\t\")\n",
    "    print(f\"K{k}\\t\", score,\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the silhouette scores to identify the best k value\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.plot(range(2,11), silhouette_score)\n",
    "ax.set_xlabel('K')\n",
    "ax.set_ylabel('Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above silhoutte scores it is clear that at k=2 we have the best score. As this is a plot of Silhoutte score vs K we need to take the global maxima. So, we wil consider the best number of clusters as 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets cluster the data with k=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering the data using k=3\n",
    "kmeans = KMeans(featuresCol = 'pca', k=2)\n",
    "model = kmeans.fit(ks_df_pca)\n",
    "ks_df_cls = model.transform(ks_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the silihoutte score of the cluster\n",
    "eval = ClusteringEvaluator(featuresCol='pca', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "silhouette = eval.evaluate(ks_df_cls)\n",
    "print(f\"Silhouette with squared euclidean distance: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the cluster centers\n",
    "centers = model.clusterCenters()\n",
    "print('Cluster Centers:')\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_cls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for splitting the pca vector\n",
    "column_names = ['pc1', 'pc2']\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only pca and state colummns for plotting.\n",
    "ks_df_sub = ks_df_pca.select('pca','state')\n",
    "ks_df_sub.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the vactor pca in to pc0 and pc1\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "def to_array(col):\n",
    "    def to_array_(v):\n",
    "        return v.toArray().tolist()\n",
    "    # Important: asNondeterministic requires Spark 2.3 or later\n",
    "    # It can be safely removed i.e.\n",
    "    # return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "    # but at the cost of decreased performance\n",
    "    return udf(to_array_, ArrayType(DoubleType())).asNondeterministic()(col)\n",
    "\n",
    "ks_df_sub1 = (ks_df_sub\n",
    "    .withColumn(\"pc\", to_array(col(\"pca\")))\n",
    "    .select([\"state\"] + [col(\"pc\")[i] for i in range(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_sub1.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the formed clusters\n",
    "ks_df_sub2 = ks_df_sub1.toPandas()\n",
    "sns.scatterplot(x='pc[0]', y='pc[1]', data=ks_df_sub2, hue='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T11:11:56.361668Z",
     "iopub.status.busy": "2022-04-14T11:11:56.361317Z",
     "iopub.status.idle": "2022-04-14T11:11:56.368588Z",
     "shell.execute_reply": "2022-04-14T11:11:56.367391Z",
     "shell.execute_reply.started": "2022-04-14T11:11:56.361631Z"
    }
   },
   "source": [
    "As the clusters seems to be inseparable, let's look at the Silhouette Coefficient of the clusters and decide what's going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the silihoutte score of the cluster\n",
    "eval = ClusteringEvaluator()\n",
    "silhouette1 = eval.evaluate(ks_df_cls)\n",
    "print(f\"Silhouette with squared euclidean distance: {silhouette1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T11:49:31.694289Z",
     "iopub.status.busy": "2022-04-14T11:49:31.69398Z",
     "iopub.status.idle": "2022-04-14T11:49:31.700382Z",
     "shell.execute_reply": "2022-04-14T11:49:31.699433Z",
     "shell.execute_reply.started": "2022-04-14T11:49:31.69425Z"
    }
   },
   "source": [
    "The Silhouette coefficient near to zero indicates that the clusters are inseparable or barely separable. It can be also be represented as the distance between the clusters is insignificant. But the score here is less than 0.4 so, we can conclude that the clusters are identifiable but the distance between them is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the machine learning implementation we are going to use the multinomial Logistic Regression algorithm. As our data is having four different classes, we are going to use the technique of passing weights of the classes to the Logistic Regression algorithm to balance the dataset. \n",
    "\n",
    "**Plan for Machine Learning Implementation**\n",
    "1. One-hot encode the categorical columns\n",
    "2. Scale the data\n",
    "3. Calculate the weights of the classes\n",
    "4. Apply the multinomial Logistic Regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking into the dataframe we need to model\n",
    "ks_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding the categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many categorical columns, let's encode them using the one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the String indexer and fitting the data to it.\n",
    "indexer = StringIndexer(inputCols=cat_cols, outputCols=cat_cols_indexed)\n",
    "ks_df = indexer.fit(ks_df).transform(ks_df)\n",
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the category column names before encoding\n",
    "cat_cols_indexed_be = ['category_indexed','main_category_indexed','currency_indexed','country_indexed']\n",
    "cat_cols_indexed\n",
    "\n",
    "# listing the category column names after encoding.\n",
    "cat_cols_indexed_ae = ['category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O']\n",
    "cat_cols_indexed_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding implementation using the indexed columns\n",
    "encoder = OneHotEncoder(inputCols=cat_cols_indexed_be, outputCols=cat_cols_indexed_ae)\n",
    "model =encoder.fit(ks_df)\n",
    "ks_df = model.transform(ks_df)\n",
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets drop the cat_cols_indexed from our dataframe ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the necessary columns\n",
    "ks_df = ks_df.select(['category', 'main_category','currency','backers','country','usd_pledged','usd_goal','launch_gap','state', 'category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O'])\n",
    "ks_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-11T22:44:49.680694Z",
     "iopub.status.busy": "2022-04-11T22:44:49.680393Z",
     "iopub.status.idle": "2022-04-11T22:44:49.68806Z",
     "shell.execute_reply": "2022-04-11T22:44:49.686725Z",
     "shell.execute_reply.started": "2022-04-11T22:44:49.680661Z"
    }
   },
   "source": [
    "As we have different ranges of values in the numerical columns we need to scale the data inorder to overcome the bias while machine learning model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of columns \n",
    "inputcols = ['backers','usd_pledged','usd_goal','launch_gap','category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O']\n",
    "inputcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dense vector of all the input features using vector assembler\n",
    "vector_assembler = VectorAssembler(inputCols=inputcols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "ks_df_scaled = vector_assembler.transform(ks_df)\n",
    "ks_df_scaled.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the standardscaler from the pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scaling on the features vector.\n",
    "standard_scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "ks_df_scaled = standard_scaler.fit(ks_df_scaled).transform(ks_df_scaled)\n",
    "ks_df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the dataframe to have only the scaled_features and labels.\n",
    "ks_df_ss = ks_df_scaled.selectExpr(\"scaled_features as features\", \"state as state\")\n",
    "ks_df_ss.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Balance of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with a multi-class classification, we need to look at the balance of the dataset and try to balance it if it is imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_ss.groupBy('state').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T13:23:45.958794Z",
     "iopub.status.busy": "2022-04-23T13:23:45.958527Z",
     "iopub.status.idle": "2022-04-23T13:23:45.969181Z",
     "shell.execute_reply": "2022-04-23T13:23:45.966249Z",
     "shell.execute_reply.started": "2022-04-23T13:23:45.958752Z"
    }
   },
   "source": [
    "As we have an imbalanced dataset. Let's try to balance it using Oversampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the data using Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ratio of weights to oversample\n",
    "failed_df = ks_df_ss.filter(col(\"state\") == 'failed')\n",
    "successful_df = ks_df_ss.filter(col(\"state\") == 'successful')\n",
    "canceled_df = ks_df_ss.filter(col(\"state\") == 'canceled')\n",
    "suspended_df = ks_df_ss.filter(col(\"state\") == 'suspended')\n",
    "\n",
    "ratio_fai_suc = int(failed_df.count()/successful_df.count())\n",
    "ratio_fai_can = int(failed_df.count()/canceled_df.count())\n",
    "ratio_fai_sus = int(failed_df.count()/suspended_df.count())\n",
    "\n",
    "print(\"ratio_fai_suc: {}\".format(ratio_fai_suc))\n",
    "print(\"ratio_fai_can: {}\".format(ratio_fai_can))\n",
    "print(\"ratio_fai_sus: {}\".format(ratio_fai_sus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual 'failed' state records are almost 2 times higher than the 'successful' records. As we got the ratio of successful projects to the failed classes as 1, we need to inspect the actual float number before rounding off and try to round it off to a higher number. To balance the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the actual ration in float\n",
    "ratio_fai_suc1 = float(failed_df.count()/successful_df.count())\n",
    "print(ratio_fai_suc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ratio is 1.76 which can be rounded of to 2 to balance the data better, we will use ratio_fai_suc+1 to oversample the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:34:28.167903Z",
     "iopub.status.busy": "2022-04-23T11:34:28.166984Z",
     "iopub.status.idle": "2022-04-23T11:34:28.172847Z",
     "shell.execute_reply": "2022-04-23T11:34:28.171677Z",
     "shell.execute_reply.started": "2022-04-23T11:34:28.167848Z"
    }
   },
   "source": [
    "## Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the minority rows in Successful state\n",
    "os_suc_df = successful_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(int(ratio_fai_suc+1))]))).drop('dummy')\n",
    "# combine both oversampled successful rows and previous majority rows \n",
    "failed_succ_df = failed_df.unionAll(os_suc_df)\n",
    "\n",
    "# duplicate the minority rows in Canceled state\n",
    "os_can_df = canceled_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(ratio_fai_can)]))).drop('dummy')\n",
    "# combine both oversampled canceled rows and previous majority rows \n",
    "failed_succ_can_df = failed_succ_df.unionAll(os_can_df)\n",
    "\n",
    "# duplicate the minority rows in Suspended state\n",
    "os_sus_df = suspended_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(ratio_fai_sus)]))).drop('dummy')\n",
    "# combine both oversampled suspended rows and previous majority rows \n",
    "ks_df_os = failed_succ_can_df.unionAll(os_sus_df)\n",
    "\n",
    "\n",
    "ks_df_os.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the balance of the data after oversampling.\n",
    "ks_df_os.groupBy('state').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data looks quite balanced with an acceptable variation among the counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:35:38.97595Z",
     "iopub.status.busy": "2022-04-23T11:35:38.975545Z",
     "iopub.status.idle": "2022-04-23T11:35:38.981312Z",
     "shell.execute_reply": "2022-04-23T11:35:38.980155Z",
     "shell.execute_reply.started": "2022-04-23T11:35:38.975908Z"
    }
   },
   "source": [
    "## Indexing the State column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the String indexer and fitting state column to it\n",
    "indexer = StringIndexer(inputCol='state', outputCol='state_indexed')\n",
    "ks_df_sliced = indexer.fit(ks_df_os).transform(ks_df_os)\n",
    "ks_df_sliced.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==0).show(1)\n",
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==1).show(1)\n",
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==2).show(1)\n",
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==3).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T17:14:31.163942Z",
     "iopub.status.busy": "2022-04-15T17:14:31.163565Z",
     "iopub.status.idle": "2022-04-15T17:14:31.170331Z",
     "shell.execute_reply": "2022-04-15T17:14:31.169222Z",
     "shell.execute_reply.started": "2022-04-15T17:14:31.163897Z"
    }
   },
   "source": [
    "From the above step it is clear that we have labels setup as below.\n",
    "\n",
    "0 --> successful\n",
    "\n",
    "1 --> failed\n",
    "\n",
    "2 --> suspended\n",
    "\n",
    "3 --> canceled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the dataframe to have only the scaled_features and labels.\n",
    "ks_df_sliced = ks_df_sliced.selectExpr(\"features as features\", \"state_indexed as labels\")\n",
    "ks_df_sliced.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the datatypes\n",
    "ks_df_sliced.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight column is read as string. we need to change it to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will split the dataset in to train and test sets randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ks_df_sliced.randomSplit([0.75, 0.25], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupBy('labels').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring and training the Logistic Regression classifier using the training data\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labels', maxIter=10)\n",
    "#lr.setWeightCol(\"weight\")\n",
    "lrModel = lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training summary.\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n",
    "# $example off$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T17:44:14.909883Z",
     "iopub.status.busy": "2022-04-15T17:44:14.908907Z",
     "iopub.status.idle": "2022-04-15T17:44:14.918958Z",
     "shell.execute_reply": "2022-04-15T17:44:14.918347Z",
     "shell.execute_reply.started": "2022-04-15T17:44:14.90973Z"
    }
   },
   "source": [
    "# Testing with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC of the model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol='labels')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.groupBy('labels', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute TN, TP, FN, and FP\n",
    "predictions.groupBy('labels', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_labels = predictions.select(['prediction','labels']).withColumn('labels', col('labels').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = preds_and_labels.select(['prediction','labels'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-0- Failed projects\n",
    "print('\\n--------------Class-0 Successful Projects----------------')\n",
    "print('True Positive Rate :', metrics.truePositiveRate(0.0))\n",
    "print('False Positive Rate:', metrics.falsePositiveRate(0.0))\n",
    "print('Precision          :', metrics.precision(0.0))\n",
    "print('recall             :', metrics.recall(0.0))\n",
    "print('f-measure          :', metrics.fMeasure(0.0))\n",
    "\n",
    "\n",
    "# Class-1- Successful projects\n",
    "print('\\n--------------Class-1 Failed Projects----------------')\n",
    "print('True Positive Rate :', metrics.truePositiveRate(1.0))\n",
    "print('False Positive Rate:', metrics.falsePositiveRate(1.0))\n",
    "print('Precision          :', metrics.precision(1.0))\n",
    "print('recall             :', metrics.recall(1.0))\n",
    "print('f-measure          :', metrics.fMeasure(1.0))\n",
    "\n",
    "# Class-2- Canclled projects\n",
    "print('\\n--------------Class-2 Suspended Projects----------------')\n",
    "print('True Positive Rate :', metrics.truePositiveRate(2.0))\n",
    "print('False Positive Rate:', metrics.falsePositiveRate(2.0))\n",
    "print('Precision          :', metrics.precision(2.0))\n",
    "print('recall             :', metrics.recall(2.0))\n",
    "print('f-measure          :', metrics.fMeasure(2.0))\n",
    "\n",
    "# Class-3- Suspended projects\n",
    "print('\\n--------------Class-3 Canceled Projects----------------')\n",
    "print('True Positive Rate :', metrics.truePositiveRate(3.0))\n",
    "print('False Positive Rate:', metrics.falsePositiveRate(3.0))\n",
    "print('Precision          :', metrics.precision(3.0))\n",
    "print('recall             :', metrics.recall(3.0))\n",
    "print('f-measure          :', metrics.fMeasure(3.0))\n",
    "\n",
    "# Overall Accuracy\n",
    "print('\\n Overall Accuracy:',metrics.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teh model performed excellent in predicting the 'Successful' state projects. It did reasonable in predicting 'Failed' and 'Suspended' states but due to the low f-measure value, these states results can be interpreted as below par. But the model performed poor in predicting the 'canceled' state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:43:41.69862Z",
     "iopub.status.busy": "2022-04-23T11:43:41.698242Z",
     "iopub.status.idle": "2022-04-23T11:43:41.705935Z",
     "shell.execute_reply": "2022-04-23T11:43:41.704612Z",
     "shell.execute_reply.started": "2022-04-23T11:43:41.69858Z"
    }
   },
   "source": [
    "As per the kickstarter's platform about section, the projects 'successful' and 'failure' states are important and the other two states are due to many other reasons outside the data. So, let's try and model the data as binary classification by only using 'successful' and 'failed' states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Using only 'Successful' and 'Failed' state projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "ks_df1 = spark.read.csv(\"../input/kickstartercleandata/dataClean.csv\", header=True, inferSchema=True)\n",
    "ks_df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't need some of the columns like launched, deadline and _c0 we will drop them along with the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the necessary columns\n",
    "ks_df1 = ks_df1.select(['category', 'main_category','currency','backers','country','usd_pledged','usd_goal','launch_gap','state'])\n",
    "ks_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the modified schema\n",
    "ks_df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the 'Canceled' and 'Suspended' state records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df1 = ks_df1.where((col('state')=='successful') | (col('state')=='failed'))\n",
    "ks_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df1.groupBy('state').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are only left with two states of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of columns \n",
    "all_cols = ks_df1.columns\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the categorical columns\n",
    "cat_cols = ['category','main_category','currency','country','state']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the category column names after indexing.\n",
    "cat_cols_indexed = ['category_indexed','main_category_indexed','currency_indexed','country_indexed', 'state_indexed']\n",
    "cat_cols_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T22:38:34.036252Z",
     "iopub.status.busy": "2022-04-15T22:38:34.035925Z",
     "iopub.status.idle": "2022-04-15T22:38:34.040652Z",
     "shell.execute_reply": "2022-04-15T22:38:34.039845Z",
     "shell.execute_reply.started": "2022-04-15T22:38:34.036217Z"
    }
   },
   "source": [
    "# Machine Learning Implementation for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the machine learning implementation we are going to use the multinomial Logistic Regression algorithm. As our data is having four different classes, we are going to use the technique of passing weights of the classes to the Logistic Regression algorithm to balance the dataset.\n",
    "\n",
    "Plan for Machine Learning Implementation\n",
    "\n",
    "1. One-hot encode the categorical columns\n",
    "2. Scale the data\n",
    "3. Calculate the weights of the classes\n",
    "4. Apply the multinomial Logistic Regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding the categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many categorical columns, let's encode them using the one-hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the String indexer and fitting the data to it.\n",
    "indexer = StringIndexer(inputCols=cat_cols, outputCols=cat_cols_indexed)\n",
    "ks_df1 = indexer.fit(ks_df1).transform(ks_df1)\n",
    "ks_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the category column names before encoding\n",
    "cat_cols_indexed_be = ['category_indexed','main_category_indexed','currency_indexed','country_indexed']\n",
    "cat_cols_indexed\n",
    "\n",
    "# listing the category column names after encoding.\n",
    "cat_cols_indexed_ae = ['category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O']\n",
    "cat_cols_indexed_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding implementation using the indexed columns\n",
    "encoder = OneHotEncoder(inputCols=cat_cols_indexed_be, outputCols=cat_cols_indexed_ae)\n",
    "model =encoder.fit(ks_df1)\n",
    "ks_df1 = model.transform(ks_df1)\n",
    "ks_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-15T22:44:18.55368Z",
     "iopub.status.busy": "2022-04-15T22:44:18.553372Z",
     "iopub.status.idle": "2022-04-15T22:44:18.559614Z",
     "shell.execute_reply": "2022-04-15T22:44:18.558468Z",
     "shell.execute_reply.started": "2022-04-15T22:44:18.553645Z"
    }
   },
   "source": [
    "Now lets drop the cat_cols_indexed from our dataframe ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the necessary columns\n",
    "ks_df1 = ks_df1.select(['category', 'main_category','currency','backers','country','usd_pledged','usd_goal','launch_gap','state', 'category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O'])\n",
    "ks_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have different ranges of values in the numerical columns we need to scale the data inorder to overcome the bias while machine learning model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of columns \n",
    "inputcols = ['backers','usd_pledged','usd_goal','launch_gap','category_indexed_O','main_category_indexed_O','currency_indexed_O','country_indexed_O']\n",
    "inputcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dense vector of all the input features using vector assembler\n",
    "vector_assembler = VectorAssembler(inputCols=inputcols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "ks_df_scaled = vector_assembler.transform(ks_df1)\n",
    "ks_df_scaled.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the standardscaler from the pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scaling on the features vector.\n",
    "standard_scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "ks_df_scaled = standard_scaler.fit(ks_df_scaled).transform(ks_df_scaled)\n",
    "ks_df_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the dataframe to have only the scaled_features and labels.\n",
    "ks_df_ss = ks_df_scaled.selectExpr(\"scaled_features as features\", \"state as state\")\n",
    "ks_df_ss.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Balance of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with a multi-class classification, we need to look at the balance of the dataset and try to balance it if it is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_ss.groupBy('state').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above counts, it is evident that the data is imbalanced. So, we need to use a balancing technique while applying the machinelearning.\n",
    "So, we will use the oversampling technique so that we won't loosing any data unlike the undersampling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the data using Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ratio of weights to oversample\n",
    "failed_df = ks_df_ss.filter(col(\"state\") == 'failed')\n",
    "successful_df = ks_df_ss.filter(col(\"state\") == 'successful')\n",
    "\n",
    "ratio_fai_suc = int(failed_df.count()/successful_df.count())\n",
    "\n",
    "print(\"ratio_fai_suc: {}\".format(ratio_fai_suc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual 'failed' state records are almost 2 times higher than the 'successful' records. As we got the ratio of successful projects to the failed classes as 1, we need to inspect the actual float number before rounding off and try to round it off to a higher number. To balance the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the actual ration in float\n",
    "ratio_fai_suc1 = float(failed_df.count()/successful_df.count())\n",
    "print(ratio_fai_suc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T11:50:50.266501Z",
     "iopub.status.busy": "2022-04-23T11:50:50.266194Z",
     "iopub.status.idle": "2022-04-23T11:50:50.273207Z",
     "shell.execute_reply": "2022-04-23T11:50:50.271796Z",
     "shell.execute_reply.started": "2022-04-23T11:50:50.266465Z"
    }
   },
   "source": [
    "As the ratio is 1.76 which can be rounded of to 2 to balance the data better, we will use ratio_fai_suc+1 to oversample the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the minority rows in successful state\n",
    "os_suc_df = successful_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(int(ratio_fai_suc+1))]))).drop('dummy')\n",
    "\n",
    "# combine both oversampled minority rows and previous majority rows \n",
    "ks_df_os = failed_df.unionAll(os_suc_df)\n",
    "\n",
    "ks_df_os.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the balance of the data after oversampling.\n",
    "ks_df_os.groupBy('state').count().orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_os.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the String indexer and fitting state column to it\n",
    "indexer = StringIndexer(inputCol='state', outputCol='state_indexed')\n",
    "ks_df_sliced = indexer.fit(ks_df_os).transform(ks_df_os)\n",
    "ks_df_sliced.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==0).show(1)\n",
    "ks_df_sliced.filter(ks_df_sliced.state_indexed==1).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above step it is clear that we have labels setup as below.\n",
    "\n",
    "0 --> successful\n",
    "\n",
    "1 --> failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the dataframe to have only the scaled_features and labels.\n",
    "ks_df_sliced = ks_df_sliced.selectExpr(\"features as features\", \"state_indexed as labels\")\n",
    "ks_df_sliced.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the datatypes\n",
    "ks_df_sliced.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will split the dataset in to train and test sets randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ks_df_sliced.randomSplit([0.75, 0.25], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring and training the Logistic Regression classifier using the training data\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'labels', maxIter=10)\n",
    "#lr.setWeightCol(\"weight\")\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training summary.\n",
    "trainingSummary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the statistics summary for the Logistic Regression model\n",
    "trainingSummary = lrModel.summary\n",
    "# plot the ROC curve from the calculated summary\n",
    "roc = trainingSummary.roc.toPandas()\n",
    "plt.plot(roc['FPR'],roc['TPR'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "print('Training set Area Under ROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = trainingSummary.pr.toPandas()\n",
    "plt.plot(pr['recall'],pr['precision'])\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n",
    "# $example off$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with the test dataset¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under ROC of the model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol='labels')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='labels')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing TruePositive, TrueNegative, FalsePositive, FalseNegative\n",
    "predictions.groupBy('labels', 'prediction').count().show()\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = predictions.filter('prediction = 0 AND labels = prediction').count()\n",
    "TP = predictions.filter('prediction = 1 AND labels = prediction').count()\n",
    "FN = predictions.filter('prediction = 0 AND labels <> prediction').count()\n",
    "FP = predictions.filter('prediction = 1 AND labels <> prediction').count()\n",
    "# calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "F = 2 * (precision*recall) / (precision + recall)\n",
    "print('precision:', precision)\n",
    "print('recall   :', recall)\n",
    "print('accuracy :', accuracy)\n",
    "print('F1 score :', F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with the above metrics, we can conclude that the data can be modeled with very good accuracy when we only use 'successful' and 'failed' state project records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
